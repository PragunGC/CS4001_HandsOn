{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c4eb73",
   "metadata": {},
   "source": [
    "## 02-02-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfecc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19f89501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84026003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d27537f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('belford', ['B', 'EH1', 'L', 'F', 'ER0', 'D'])\n",
      "('belfry', ['B', 'EH1', 'L', 'F', 'R', 'IY0'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'G', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'JH', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgard', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D'])\n",
      "('belgarde', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D', 'IY0'])\n",
      "('belge', ['B', 'EH1', 'L', 'JH', 'IY0'])\n",
      "('belger', ['B', 'EH1', 'L', 'G', 'ER0'])\n",
      "('belgian', ['B', 'EH1', 'L', 'JH', 'AH0', 'N'])\n",
      "('belgians', ['B', 'EH1', 'L', 'JH', 'AH0', 'N', 'Z'])\n",
      "('belgique', ['B', 'EH0', 'L', 'ZH', 'IY1', 'K'])\n",
      "(\"belgique's\", ['B', 'EH0', 'L', 'JH', 'IY1', 'K', 'S'])\n",
      "('belgium', ['B', 'EH1', 'L', 'JH', 'AH0', 'M'])\n",
      "(\"belgium's\", ['B', 'EH1', 'L', 'JH', 'AH0', 'M', 'Z'])\n",
      "('belgo', ['B', 'EH1', 'L', 'G', 'OW2'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D', 'Z'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D', 'Z'])\n",
      "('belgrave', ['B', 'EH1', 'L', 'G', 'R', 'EY2', 'V'])\n",
      "('beli', ['B', 'EH1', 'L', 'IY0'])\n",
      "('belich', ['B', 'EH1', 'L', 'IH0', 'K'])\n",
      "('belie', ['B', 'IH0', 'L', 'AY1'])\n",
      "('belied', ['B', 'IH0', 'L', 'AY1', 'D'])\n",
      "('belief', ['B', 'IH0', 'L', 'IY1', 'F'])\n"
     ]
    }
   ],
   "source": [
    "for entry in entries[10000:10025]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6b4e955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bottle.n.01'),\n",
       " Synset('bottle.n.02'),\n",
       " Synset('bottle.n.03'),\n",
       " Synset('bottle.v.01'),\n",
       " Synset('bottle.v.02')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('bottle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81308dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bottle']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('bottle.v.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd453926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmerporter = PorterStemmer()\n",
    "stemmerporter.stem('Singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "318247e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmerporter = LancasterStemmer()\n",
    "stemmerporter.stem('Singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "826f6a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Work'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmerporter = RegexpStemmer('ing') #Substring to remove from word\n",
    "stemmerporter.stem('Working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b8565e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages #International Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c395b46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mang'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frenchstemmer = SnowballStemmer('french')\n",
    "frenchstemmer.stem('manges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b437bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = \"\"\"A census is the procedure of systematically acquiring, recording and calculating population information about the members of a given population. This term is used mostly in connection with national population and housing censuses; other common censuses include censuses of agriculture, traditional culture, business, supplies, and traffic censuses. The United Nations (UN) defines the essential features of population and housing censuses as \"individual enumeration, universality within a defined territory, simultaneity and defined periodicity\", and recommends that population censuses be taken at least every ten years. UN recommendations also cover census topics to be collected, official definitions, classifications and other useful information to co-ordinate international practices.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef97a923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A census is the procedure of systematically acquiring, recording and calculating population information about the members of a given population.', 'This term is used mostly in connection with national population and housing censuses; other common censuses include censuses of agriculture, traditional culture, business, supplies, and traffic censuses.', 'The United Nations (UN) defines the essential features of population and housing censuses as \"individual enumeration, universality within a defined territory, simultaneity and defined periodicity\", and recommends that population censuses be taken at least every ten years.', 'UN recommendations also cover census topics to be collected, official definitions, classifications and other useful information to co-ordinate international practices.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(texts)\n",
    "print(sentences)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c21f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('census', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('procedure', 'NN'), ('of', 'IN'), ('systematically', 'RB'), ('acquiring', 'VBG'), (',', ','), ('recording', 'VBG'), ('and', 'CC'), ('calculating', 'VBG'), ('population', 'NN'), ('information', 'NN'), ('about', 'IN'), ('the', 'DT'), ('members', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('given', 'VBN'), ('population', 'NN'), ('.', '.')]\n",
      "[('This', 'DT'), ('term', 'NN'), ('is', 'VBZ'), ('used', 'VBN'), ('mostly', 'RB'), ('in', 'IN'), ('connection', 'NN'), ('with', 'IN'), ('national', 'JJ'), ('population', 'NN'), ('and', 'CC'), ('housing', 'NN'), ('censuses', 'NNS'), (';', ':'), ('other', 'JJ'), ('common', 'JJ'), ('censuses', 'NNS'), ('include', 'VBP'), ('censuses', 'NNS'), ('of', 'IN'), ('agriculture', 'NN'), (',', ','), ('traditional', 'JJ'), ('culture', 'NN'), (',', ','), ('business', 'NN'), (',', ','), ('supplies', 'NNS'), (',', ','), ('and', 'CC'), ('traffic', 'NN'), ('censuses', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('United', 'NNP'), ('Nations', 'NNP'), ('(', '('), ('UN', 'NNP'), (')', ')'), ('defines', 'VBZ'), ('the', 'DT'), ('essential', 'JJ'), ('features', 'NNS'), ('of', 'IN'), ('population', 'NN'), ('and', 'CC'), ('housing', 'NN'), ('censuses', 'NNS'), ('as', 'IN'), ('``', '``'), ('individual', 'JJ'), ('enumeration', 'NN'), (',', ','), ('universality', 'NN'), ('within', 'IN'), ('a', 'DT'), ('defined', 'JJ'), ('territory', 'NN'), (',', ','), ('simultaneity', 'NN'), ('and', 'CC'), ('defined', 'VBD'), ('periodicity', 'NN'), (\"''\", \"''\"), (',', ','), ('and', 'CC'), ('recommends', 'VBZ'), ('that', 'DT'), ('population', 'NN'), ('censuses', 'VBZ'), ('be', 'VB'), ('taken', 'VBN'), ('at', 'IN'), ('least', 'JJS'), ('every', 'DT'), ('ten', 'CD'), ('years', 'NNS'), ('.', '.')]\n",
      "[('UN', 'NNP'), ('recommendations', 'NNS'), ('also', 'RB'), ('cover', 'VBP'), ('census', 'NN'), ('topics', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('collected', 'VBN'), (',', ','), ('official', 'JJ'), ('definitions', 'NNS'), (',', ','), ('classifications', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('useful', 'JJ'), ('information', 'NN'), ('to', 'TO'), ('co-ordinate', 'JJ'), ('international', 'JJ'), ('practices', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    #print(word)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc332e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "f = open('tweets.1','r')\n",
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94bb62c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 1 of 1 matches:\n",
      " include censuses of agriculture, traditional culture, business, supplies, and \n"
     ]
    }
   ],
   "source": [
    "text1 = texts.split()\n",
    "text2 = nltk.Text(text1)\n",
    "text2.concordance(\"traditional\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS1",
   "language": "python",
   "name": "ds1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
